#Pruning and Quantinization 
import os
import cv2
import numpy as np
from google.colab import files

! pip install patchify
! pip install segmentation-models
! pip install tensorflow
! pip install tensorflow_model_optimization
! pip install nni.compression.torch 

import os
import cv2
import sys
import tensorflow as tf
import numpy as np
import tempfile

from matplotlib import pyplot as plt
from patchify import patchify
from PIL import Image
import segmentation_models as sm
from tensorflow.keras.metrics import MeanIoU
import tensorflow_model_optimization as tfmot
from tensorflow import keras
import torch

from sklearn.preprocessing import MinMaxScaler, StandardScaler
scaler = MinMaxScaler()

root_directory = 'semseg_repo/nni/Semantic segmentation dataset/'

patch_size = 256
image_dataset = []  
for path, subdirs, files in os.walk(root_directory):
    #print(path)  
    dirname = path.split(os.path.sep)[-1]
    if dirname == 'images':  
        images = os.listdir(path) 
        images.sort()
        for i, image_name in enumerate(images):  
            if image_name.endswith(".jpg"):   
               
                image = cv2.imread(path+"/"+image_name, 1) 
                SIZE_X = (image.shape[1]//patch_size)*patch_size 
                SIZE_Y = (image.shape[0]//patch_size)*patch_size
                image = Image.fromarray(image)
                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  
                image = np.array(image)             
                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)
        
                for i in range(patches_img.shape[0]):
                    for j in range(patches_img.shape[1]):
                        
                        single_patch_img = patches_img[i,j,:,:]
                        single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)
                        single_patch_img = single_patch_img[0]                                
                        image_dataset.append(single_patch_img)
mask_dataset = []  
for path, subdirs, files in os.walk(root_directory):
    #print(path)  
    dirname = path.split(os.path.sep)[-1]
    if dirname == 'masks':  
        masks = os.listdir(path) 
        masks.sort()
        for i, mask_name in enumerate(masks):  
            if mask_name.endswith(".png"):  
               
                mask = cv2.imread(path+"/"+mask_name, 1)  
                mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)
                SIZE_X = (mask.shape[1]//patch_size)*patch_size 
                SIZE_Y = (mask.shape[0]//patch_size)*patch_size 
                mask = Image.fromarray(mask)
                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y)) 
                mask = np.array(mask)             
                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size) 
        
                for i in range(patches_mask.shape[0]):
                    for j in range(patches_mask.shape[1]):
                        
                        single_patch_mask = patches_mask[i,j,:,:]
                     
                        single_patch_mask = single_patch_mask[0]                              
                        mask_dataset.append(single_patch_mask) 
 
image_dataset = np.array(image_dataset)
mask_dataset =  np.array(mask_dataset)


a=int('3C', 16) 
Building = '#3C1098'.lstrip('#')
Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) 
Land = '#8429F6'.lstrip('#')
Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) 
Road = '#6EC1E4'.lstrip('#') 
Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4)))
Vegetation =  'FEDD3A'.lstrip('#') 
Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) 
Water = 'E2A929'.lstrip('#') 
Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4)))
Unlabeled = '#9B9B9B'.lstrip('#') 
Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) 
label = single_patch_mask

def rgb_to_2D_label(label):
    """
    Suply our labale masks as input in RGB format. 
    Replace pixels with specific RGB values ...
    """
    label_seg = np.zeros(label.shape,dtype=np.uint8)
    label_seg [np.all(label == Building,axis=-1)] = 0
    label_seg [np.all(label==Land,axis=-1)] = 1
    label_seg [np.all(label==Road,axis=-1)] = 2
    label_seg [np.all(label==Vegetation,axis=-1)] = 3
    label_seg [np.all(label==Water,axis=-1)] = 4
    label_seg [np.all(label==Unlabeled,axis=-1)] = 5 
    label_seg = label_seg[:,:,0]  
    return label_seg
labels = []
for i in range(mask_dataset.shape[0]):
    label = rgb_to_2D_label(mask_dataset[i])
    labels.append(label)    

labels = np.array(labels)   
labels = np.expand_dims(labels, axis=3)


n_classes = len(np.unique(labels))
from keras.utils import to_categorical
labels_cat = to_categorical(labels, num_classes=n_classes)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)

############################################################################

#Optimized parameters for model

optimized_params = {
    'learning_rate': 0.0004678418249479461,
    'activation_type': 'relu',
    'batch_size': 4
}

weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]
dice_loss = sm.losses.DiceLoss(class_weights=weights) 
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]

from semseg_repo.nni.simple_multi_unet_model_optimized import multi_unet_model_optimized, jacard_coef  

metrics=['accuracy', jacard_coef]
#Create model
def get_model():
    return multi_unet_model_optimized(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS, activation_type=optimized_params['activation_type'])

model = get_model()

adam = tf.keras.optimizers.Adam(learning_rate=optimized_params['learning_rate'])

#Define pruning and quantizer parameters
initial_sparsity = 0.0
final_sparsity = 0.75
begin_step = 1000
end_step = 5000

pruning_params = {
      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.80, begin_step=0,end_step=end_step)
}

#Apply pruning 
model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()

model.compile(optimizer=adam, loss=total_loss, metrics=metrics)

history1 = model.fit(X_train, y_train,
                  batch_size=4, epochs=100,  validation_data=(X_test, y_test),
                  callbacks=pruning_callback)
#ac loss
history = history1
loss = history.history['loss']

val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['jacard_coef']
val_acc = history.history['val_jacard_coef']

plt.plot(epochs, acc, 'y', label='Training IoU')
plt.plot(epochs, val_acc, 'r', label='Validation IoU')
plt.title('Training and validation IoU')
plt.xlabel('Epochs')
plt.ylabel('IoU')
plt.legend()
plt.show()

##################################

from keras.models import load_model

#IOU
y_pred=model.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=3)
y_test_argmax=np.argmax(y_test, axis=3)
from keras.metrics import MeanIoU
n_classes = 6
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())
y_pred_argmax_normalized = tf.math.divide(tf.math.subtract(y_pred_argmax, tf.math.reduce_min(y_pred_argmax)), tf.math.subtract(tf.math.reduce_max(y_pred_argmax), tf.math.reduce_min(y_pred_argmax)))
y_test_argmax_normalized = tf.math.divide(tf.math.subtract(y_test_argmax, tf.math.reduce_min(y_test_argmax)), tf.math.subtract(tf.math.reduce_max(y_test_argmax), tf.math.reduce_min(y_test_argmax)))

precision_list = []
recall_list = []
threshold_list = np.arange(0.0, 1.0, 0.001, dtype=float)
for threshold in threshold_list:
  precision_sum = 0
  recall_sum = 0

  for i in range(n_classes):
    precision_keras = tf.keras.metrics.Precision(class_id = i, thresholds = threshold)
    precision_keras.update_state(y_test_argmax_normalized, y_pred_argmax_normalized)
    precision_sum += precision_keras.result().numpy()
    recall_keras = tf.keras.metrics.Recall(class_id = i, thresholds = threshold)
    recall_keras.update_state(y_test_argmax_normalized, y_pred_argmax_normalized)
    recall_sum += recall_keras.result().numpy()

  mean_precision = precision_sum / n_classes
  mean_recall = recall_sum / n_classes

  precision_list.append(mean_precision)
  recall_list.append(mean_recall)

recall_list.append(0)
precision_list.append(1)

recall_list.insert(0, 1)
precision_list.insert(0, 0)

plt.plot(recall_list, precision_list, 'b')
plt.title("Precision Recall Curve")
plt.xlabel('Recall')
plt.ylabel('Presicion')

import random
for i in range(10): 
  test_img_number = random.randint(0, len(X_test) - 1)
  test_img = X_test[test_img_number]
  ground_truth=y_test_argmax[test_img_number]
  test_img_norm=test_img[:,:,0][:,:,None]
  test_img_input=np.expand_dims(test_img, 0)
  prediction = (model.predict(test_img_input))
  predicted_img=np.argmax(prediction, axis=3)[0,:,:]


  plt.figure(figsize=(12, 8))
  plt.subplot(231)
  plt.title('Testing Image')
  plt.imshow(test_img)
  plt.subplot(232)
  plt.title('Testing Label')
  plt.imshow(ground_truth)
  plt.subplot(233)
  plt.title('Prediction on test image')
  plt.imshow(predicted_img)
  plt.show()

#Compress model to smaller size for better memory
import pathlib
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

model = converter.convert()

tflite_models_dir = pathlib.Path("/tmp/mnist_tflite_models/")
tflite_models_dir.mkdir(exist_ok=True, parents=True)

tflite_model_file = tflite_models_dir/"mnist_model.tflite"
tflite_model_file.write_bytes(model)

interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))
interpreter.allocate_tensors()

interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_file))
interpreter_quant.allocate_tensors()


arr = np.array([0,1,2,3,4,5,6,7,8,9])
for i in arr:
  input_index = interpreter.get_input_details()[0]["index"]
  output_index = interpreter.get_output_details()[0]["index"]

 
  test_image = np.expand_dims(X_test[i], axis=0).astype(np.float32)

  
  interpreter.set_tensor(input_index, test_image)

  interpreter.invoke()


  output = interpreter.get_tensor(output_index)

  test_img = X_test[i]
  ground_truth=y_test_argmax[i]
  test_img_norm=test_img[:,:,0][:,:,None]
  test_img_input=np.expand_dims(test_img, 0)
  prediction = output
  pred_img = np.argmax(prediction, axis=3)[0,:,:]


  plt.figure(figsize=(12, 8))
  plt.subplot(231)
  plt.title('Testing Image')
  plt.imshow(test_img)
  plt.subplot(232)
  plt.title('Testing Label')
  plt.imshow(ground_truth)
  plt.subplot(233)
  plt.title('Prediction on test image  from compressed model')
  plt.imshow(pred_img)
  plt.grid(False)
  plt.show()
